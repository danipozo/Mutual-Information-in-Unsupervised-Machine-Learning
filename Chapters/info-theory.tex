Obtaining good representations of data is one of the most important tasks in Machine learning. Good features of our data will lead us to easier and more accurate training on \emph{Artificial Neural Networks (ANNs)} and, thus, better results on experiments.

Recently, it has been discovered that maximizing \emph{Mutual Information} between two elements in our data can give us good representations for our data. We will go through the basic concepts first.

The \emph{mutual information} concept is based on the \emph{Shannon entropy}, which we will introduce first, along with some basic properties of it. The \emph{Shannon entropy} its a way of measuring the uncertainty in a random variable. Given an event $\mathcal A \in \Omega$, $\Prob$ a probability measure and $\Prob[\A]$ the probability of $\mathcal A$, we can affirm that 
$$
log\frac{1}{\Prob[\mathcal A]}
$$
describes \emph{how surprising is that $\A$ occurs}. For instance, if $P[\A] = 1$, then the last expression is zero, which means that it is not a surprise that $\A$ occurred. With this motivation, we get to the following definition.

\begin{ndef}
Let $\X$ be a random variable. The \emph{Shannon entropy}, or simply \emph{entropy} , $H(\X)$ of $\X$ is defined as:
$$
H(\X) = E_\X[log\frac{1}{\Prob(\X)}] =  \sum_{x \in \X} P_\X(x) log\frac{1}{\Prob(x)}
$$
\end{ndef}

% Define shannon entropy

% Do I have to define it for the continuous case?
% Will I use the continuous or the discrete case?

% Proposition of cotes